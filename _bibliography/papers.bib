---
---

@article{lu2025contrastive,
  title={Contrastive Gradient Guidance for Test-time Preference Alignment of Diffusion Models},
  author={Po-Yi Lu, Jui-Chao Lu, Paul Kuo-Ming Huang, Chun-Liang Li, Hsuan-Tien Lin},
  journal={manuscript submitted for publication},
  year={2025},
  selected={true},
  html={https://openreview.net/forum?id=g9aaKXgFhK}
}

@inproceedings{lee-etal-2025-compound,
    title={Compound {AI} Systems Optimization: A Survey of Methods, Challenges, and Future Directions},
    author={Lee, Yu-Ang and ... and Lu, Jui-Chao  and...  and Chen, Yun-Nung},
    year={2025},
    booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
    publisher={Association for Computational Linguistics},
    url={https://aclanthology.org/2025.emnlp-main.1463/},
    doi={10.18653/v1/2025.emnlp-main.1463},
    abstract={Recent advancements in large language models (LLMs) and AI systems have led to a paradigm shift in the design and optimization of complex AI workflows. By integrating multiple components, compound AI systems have become increasingly adept at performing sophisticated tasks. However, as these systems grow in complexity, new challenges arise in optimizing not only individual components but also their interactions. While traditional optimization methods such as supervised fine-tuning (SFT) and reinforcement learning (RL) remain foundational, the rise of natural language feedback introduces promising new approaches, especially for optimizing non-differentiable systems. This paper provides a systematic review of recent progress in optimizing compound AI systems, encompassing both numerical and language-based techniques. We formalize the notion of compound AI system optimization, classify existing methods along several key dimensions, and highlight open research challenges and future directions in this rapidly evolving field."
}


